{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd, numpy as np, re, time\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "sns.set(style = \"whitegrid\", color_codes = True,font_scale = 1.5)\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train-balanced-sarcasm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "### Figuring out the \"nan\" float values that are causing issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010826\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label             False\n",
      "comment            True\n",
      "author            False\n",
      "subreddit         False\n",
      "score             False\n",
      "ups               False\n",
      "downs             False\n",
      "date              False\n",
      "created_utc       False\n",
      "parent_comment    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().any(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010826\n",
      "1010826\n"
     ]
    }
   ],
   "source": [
    "features = df['comment']\n",
    "labels = df['label']\n",
    "print(len(features))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "i_count: 1010826\n",
      "bad_indices: [56269, 68590, 135348, 199910, 258718, 284331, 312969, 328775, 331735, 332600, 332631, 362293, 389792, 445204, 505371, 520619, 524263, 529336, 532823, 569280, 645450, 651242, 661519, 675235, 683899, 747602, 799033, 800812, 813274, 817886, 859333, 875251, 878050, 898863, 905291, 914178, 914615, 918700, 919882, 923678, 936221, 949593, 966886, 967116, 978220, 982492, 992907, 995023, 1001185, 1001891, 1002133, 1009303, 1010599]\n",
      "0.6761200428009033 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "counter = 0\n",
    "i_count = 0\n",
    "bad_indices = []\n",
    "\n",
    "for i,string in enumerate(features):\n",
    "    try:\n",
    "        if isinstance(string, float):\n",
    "            counter += 1\n",
    "            bad_indices.append(i_count)\n",
    "    except:\n",
    "        pass\n",
    "    i_count += 1\n",
    "\n",
    "print(counter)\n",
    "print(\"i_count:\", i_count)\n",
    "print(\"bad_indices:\", bad_indices)\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010826\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010773\n"
     ]
    }
   ],
   "source": [
    "for b in bad_indices:\n",
    "    df = df.drop([b])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010773\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010773\n",
      "1010773\n"
     ]
    }
   ],
   "source": [
    "features = df['comment']\n",
    "labels = df['label']\n",
    "print(len(features))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "i_count 1010773\n",
      "2.423959970474243 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "counter = 0\n",
    "i_count = 0\n",
    "for i in df.itertuples():\n",
    "    if not i[2]:\n",
    "        counter += 1\n",
    "        print(counter)\n",
    "    i_count += 1\n",
    "\n",
    "print(counter)\n",
    "print(\"i_count\", i_count)\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select desired sample size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "sample_size = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(int(sample_size))\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "features = df['comment']\n",
    "labels = df['label']\n",
    "print(len(features))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming data: reducing a word to its word stem\n",
    "ps = PorterStemmer()\n",
    "features = features.apply(lambda x: x.split())\n",
    "features = features.apply(lambda x : ' '.join([ps.stem(word) for word in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.09518074989319 seconds\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF: Transoform text to meaningful numerical representation\n",
    "tv = TfidfVectorizer(max_features = 5000)\n",
    "# features = list(features)\n",
    "features = tv.fit_transform(features).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing data\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = .05, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7065368421052631\n",
      "0.6554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.67      2491\n",
      "           1       0.67      0.62      0.64      2509\n",
      "\n",
      "    accuracy                           0.66      5000\n",
      "   macro avg       0.66      0.66      0.66      5000\n",
      "weighted avg       0.66      0.66      0.66      5000\n",
      "\n",
      "7.412353992462158 seconds\n"
     ]
    }
   ],
   "source": [
    "# Using linear support vector classifier\n",
    "start = time.time()\n",
    "\n",
    "lsvc = LinearSVC()\n",
    "lsvc.fit(features_train, labels_train)\n",
    "test_predicted_labels = lsvc.predict(features_test)\n",
    "print(lsvc.score(features_train, labels_train))\n",
    "print(lsvc.score(features_test, labels_test))\n",
    "print(classification_report(labels_test, test_predicted_labels))\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6425263157894737\n",
      "0.577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56      2491\n",
      "           1       0.57      0.62      0.59      2509\n",
      "\n",
      "    accuracy                           0.58      5000\n",
      "   macro avg       0.58      0.58      0.58      5000\n",
      "weighted avg       0.58      0.58      0.58      5000\n",
      "\n",
      "247.18753910064697 seconds\n"
     ]
    }
   ],
   "source": [
    "# Using Gaussian Naive Bayes\n",
    "start = time.time()\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(features_train, labels_train)\n",
    "print(gnb.score(features_train, labels_train))\n",
    "print(gnb.score(features_test, labels_test))\n",
    "test_predicted_labels = gnb.predict(features_test)\n",
    "print(classification_report(labels_test, test_predicted_labels))\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7046105263157895\n",
      "0.6622\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.67      2491\n",
      "           1       0.68      0.63      0.65      2509\n",
      "\n",
      "    accuracy                           0.66      5000\n",
      "   macro avg       0.66      0.66      0.66      5000\n",
      "weighted avg       0.66      0.66      0.66      5000\n",
      "\n",
      "6.7619709968566895 seconds\n"
     ]
    }
   ],
   "source": [
    "# Using Logistic Regression\n",
    "start = time.time()\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features_train, labels_train)\n",
    "print(lr.score(features_train, labels_train))\n",
    "print(lr.score(features_test, labels_test))\n",
    "test_predicted_labels = lr.predict(features_test)\n",
    "print(classification_report(labels_test, test_predicted_labels))\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9635263157894737\n",
      "0.6404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66      2491\n",
      "           1       0.66      0.58      0.62      2509\n",
      "\n",
      "    accuracy                           0.64      5000\n",
      "   macro avg       0.64      0.64      0.64      5000\n",
      "weighted avg       0.64      0.64      0.64      5000\n",
      "\n",
      "300.66705083847046 seconds\n"
     ]
    }
   ],
   "source": [
    "# Using Random Forest Classification\n",
    "start = time.time()\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 10, random_state = 0)\n",
    "rfc.fit(features_train, labels_train)\n",
    "print(rfc.score(features_train, labels_train))\n",
    "print(rfc.score(features_test, labels_test))\n",
    "test_predicted_labels = rfc.predict(features_test)\n",
    "print(classification_report(labels_test, test_predicted_labels))\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"News Headline\" Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://github.com/rishabhmisra/News-Headlines-Dataset-For-Sarcasm-Detection\n",
    "# NOTES - Dataset is much cleaner, less spelling errors, higher modeling scores overall\n",
    "df = pd.read_json(\"Sarcasm_Headlines_Dataset.json\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28619\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.theonion.com/thirtysomething-scien...   \n",
       "1  https://www.huffingtonpost.com/entry/donna-edw...   \n",
       "2  https://www.huffingtonpost.com/entry/eat-your-...   \n",
       "3  https://local.theonion.com/inclement-weather-p...   \n",
       "4  https://www.theonion.com/mother-comes-pretty-c...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  thirtysomething scientists unveil doomsday clo...             1  \n",
       "1  dem rep. totally nails why congress is falling...             0  \n",
       "2  eat your veggies: 9 deliciously different recipes             0  \n",
       "3  inclement weather prevents liar from getting t...             1  \n",
       "4  mother comes pretty close to using word 'strea...             1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28619\n",
      "28619\n"
     ]
    }
   ],
   "source": [
    "features = df['headline']\n",
    "labels = df['is_sarcastic']\n",
    "print(len(features))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming data: reducing a word to its word stem\n",
    "ps = PorterStemmer()\n",
    "features = features.apply(lambda x: x.split())\n",
    "features = features.apply(lambda x : ' '.join([ps.stem(word) for word in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF: Transoform text to meaningful numerical representation\n",
    "tv = TfidfVectorizer(max_features = 5000)\n",
    "# features = list(features)\n",
    "features = tv.fit_transform(features).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing data\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = .05, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9050684125349419\n",
      "0.8218029350104822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82       717\n",
      "           1       0.82      0.83      0.82       714\n",
      "\n",
      "    accuracy                           0.82      1431\n",
      "   macro avg       0.82      0.82      0.82      1431\n",
      "weighted avg       0.82      0.82      0.82      1431\n",
      "\n",
      "0.7443058490753174 seconds\n"
     ]
    }
   ],
   "source": [
    "# Using linear support vector classifier\n",
    "start = time.time()\n",
    "\n",
    "lsvc = LinearSVC()\n",
    "lsvc.fit(features_train, labels_train)\n",
    "test_predicted_labels = lsvc.predict(features_test)\n",
    "print(lsvc.score(features_train, labels_train))\n",
    "print(lsvc.score(features_test, labels_test))\n",
    "print(classification_report(labels_test, test_predicted_labels))\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8031852287774018\n",
      "0.7169811320754716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.73       717\n",
      "           1       0.74      0.66      0.70       714\n",
      "\n",
      "    accuracy                           0.72      1431\n",
      "   macro avg       0.72      0.72      0.72      1431\n",
      "weighted avg       0.72      0.72      0.72      1431\n",
      "\n",
      "12.7919020652771 seconds\n"
     ]
    }
   ],
   "source": [
    "# Using Gaussian Naive Bayes\n",
    "start = time.time()\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(features_train, labels_train)\n",
    "print(gnb.score(features_train, labels_train))\n",
    "print(gnb.score(features_test, labels_test))\n",
    "test_predicted_labels = gnb.predict(features_test)\n",
    "print(classification_report(labels_test, test_predicted_labels))\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8796527879947036\n",
      "0.8301886792452831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83       717\n",
      "           1       0.82      0.85      0.83       714\n",
      "\n",
      "    accuracy                           0.83      1431\n",
      "   macro avg       0.83      0.83      0.83      1431\n",
      "weighted avg       0.83      0.83      0.83      1431\n",
      "\n",
      "0.58504319190979 seconds\n"
     ]
    }
   ],
   "source": [
    "# Using Logistic Regression\n",
    "start = time.time()\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features_train, labels_train)\n",
    "print(lr.score(features_train, labels_train))\n",
    "print(lr.score(features_test, labels_test))\n",
    "test_predicted_labels = lr.predict(features_test)\n",
    "print(classification_report(labels_test, test_predicted_labels))\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9900691481535971\n",
      "0.777078965758211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78       717\n",
      "           1       0.78      0.77      0.78       714\n",
      "\n",
      "    accuracy                           0.78      1431\n",
      "   macro avg       0.78      0.78      0.78      1431\n",
      "weighted avg       0.78      0.78      0.78      1431\n",
      "\n",
      "32.20409893989563 seconds\n"
     ]
    }
   ],
   "source": [
    "# Using Random Forest Classification\n",
    "start = time.time()\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 10, random_state = 0)\n",
    "rfc.fit(features_train, labels_train)\n",
    "print(rfc.score(features_train, labels_train))\n",
    "print(rfc.score(features_test, labels_test))\n",
    "test_predicted_labels = rfc.predict(features_test)\n",
    "print(classification_report(labels_test, test_predicted_labels))\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
