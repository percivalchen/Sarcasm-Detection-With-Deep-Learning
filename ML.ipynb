{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd, numpy as np, re, time\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "sns.set(style = \"whitegrid\", color_codes = True,font_scale = 1.5)\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Reddit_Dataset_Cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010773\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010773\n",
      "1010773\n"
     ]
    }
   ],
   "source": [
    "features = df['comment']\n",
    "labels = df['label']\n",
    "print(len(features))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(28619)\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010773\n",
      "1010773\n"
     ]
    }
   ],
   "source": [
    "features = df['comment']\n",
    "labels = df['label']\n",
    "print(len(features))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming data: reducing a word to its word stem\n",
    "ps = PorterStemmer()\n",
    "features = features.apply(lambda x: x.split())\n",
    "features = features.apply(lambda x : ' '.join([ps.stem(word) for word in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224.01524662971497 seconds\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF: Transoform text to meaningful numerical representation\n",
    "tv = TfidfVectorizer(max_features = 5000)\n",
    "# features = list(features)\n",
    "features = tv.fit_transform(features).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing data\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = .05, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using linear support vector classifier\n",
    "start = time.time()\n",
    "\n",
    "lsvc = LinearSVC()\n",
    "lsvc.fit(features_train, labels_train)\n",
    "test_predicted_labels = lsvc.predict(features_test)\n",
    "print(lsvc.score(features_train, labels_train))\n",
    "print(lsvc.score(features_test, labels_test))\n",
    "print(classification_report(labels_test, test_predicted_labels))\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Gaussian Naive Bayes\n",
    "start = time.time()\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(features_train, labels_train)\n",
    "print(gnb.score(features_train, labels_train))\n",
    "print(gnb.score(features_test, labels_test))\n",
    "test_predicted_labels = gnb.predict(features_test)\n",
    "print(classification_report(labels_test, test_predicted_labels))\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Logistic Regression\n",
    "start = time.time()\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features_train, labels_train)\n",
    "print(lr.score(features_train, labels_train))\n",
    "print(lr.score(features_test, labels_test))\n",
    "test_predicted_labels = lr.predict(features_test)\n",
    "print(classification_report(labels_test, test_predicted_labels))\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Random Forest Classification\n",
    "start = time.time()\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 10, random_state = 0)\n",
    "rfc.fit(features_train, labels_train)\n",
    "print(rfc.score(features_train, labels_train))\n",
    "print(rfc.score(features_test, labels_test))\n",
    "test_predicted_labels = rfc.predict(features_test)\n",
    "print(classification_report(labels_test, test_predicted_labels))\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"News Headline\" Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://github.com/rishabhmisra/News-Headlines-Dataset-For-Sarcasm-Detection\n",
    "# NOTES - Dataset is much cleaner, less spelling errors, higher modeling scores overall\n",
    "df = pd.read_json(\"Sarcasm_Headlines_Dataset.json\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28619\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.theonion.com/thirtysomething-scien...   \n",
       "1  https://www.huffingtonpost.com/entry/donna-edw...   \n",
       "2  https://www.huffingtonpost.com/entry/eat-your-...   \n",
       "3  https://local.theonion.com/inclement-weather-p...   \n",
       "4  https://www.theonion.com/mother-comes-pretty-c...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  thirtysomething scientists unveil doomsday clo...             1  \n",
       "1  dem rep. totally nails why congress is falling...             0  \n",
       "2  eat your veggies: 9 deliciously different recipes             0  \n",
       "3  inclement weather prevents liar from getting t...             1  \n",
       "4  mother comes pretty close to using word 'strea...             1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28619\n",
      "28619\n"
     ]
    }
   ],
   "source": [
    "features = df['headline']\n",
    "labels = df['is_sarcastic']\n",
    "print(len(features))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming data: reducing a word to its word stem\n",
    "ps = PorterStemmer()\n",
    "features = features.apply(lambda x: x.split())\n",
    "features = features.apply(lambda x : ' '.join([ps.stem(word) for word in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF: Transoform text to meaningful numerical representation\n",
    "tv = TfidfVectorizer(max_features = 5000)\n",
    "# features = list(features)\n",
    "features = tv.fit_transform(features).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing data\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = .05, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9050684125349419\n",
      "0.8218029350104822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82       717\n",
      "           1       0.82      0.83      0.82       714\n",
      "\n",
      "    accuracy                           0.82      1431\n",
      "   macro avg       0.82      0.82      0.82      1431\n",
      "weighted avg       0.82      0.82      0.82      1431\n",
      "\n",
      "0.7443058490753174 seconds\n"
     ]
    }
   ],
   "source": [
    "# Using linear support vector classifier\n",
    "start = time.time()\n",
    "\n",
    "lsvc = LinearSVC()\n",
    "lsvc.fit(features_train, labels_train)\n",
    "test_predicted_labels = lsvc.predict(features_test)\n",
    "print(lsvc.score(features_train, labels_train))\n",
    "print(lsvc.score(features_test, labels_test))\n",
    "print(classification_report(labels_test, test_predicted_labels))\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8031852287774018\n",
      "0.7169811320754716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.73       717\n",
      "           1       0.74      0.66      0.70       714\n",
      "\n",
      "    accuracy                           0.72      1431\n",
      "   macro avg       0.72      0.72      0.72      1431\n",
      "weighted avg       0.72      0.72      0.72      1431\n",
      "\n",
      "12.7919020652771 seconds\n"
     ]
    }
   ],
   "source": [
    "# Using Gaussian Naive Bayes\n",
    "start = time.time()\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(features_train, labels_train)\n",
    "print(gnb.score(features_train, labels_train))\n",
    "print(gnb.score(features_test, labels_test))\n",
    "test_predicted_labels = gnb.predict(features_test)\n",
    "print(classification_report(labels_test, test_predicted_labels))\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8796527879947036\n",
      "0.8301886792452831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83       717\n",
      "           1       0.82      0.85      0.83       714\n",
      "\n",
      "    accuracy                           0.83      1431\n",
      "   macro avg       0.83      0.83      0.83      1431\n",
      "weighted avg       0.83      0.83      0.83      1431\n",
      "\n",
      "0.58504319190979 seconds\n"
     ]
    }
   ],
   "source": [
    "# Using Logistic Regression\n",
    "start = time.time()\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features_train, labels_train)\n",
    "print(lr.score(features_train, labels_train))\n",
    "print(lr.score(features_test, labels_test))\n",
    "test_predicted_labels = lr.predict(features_test)\n",
    "print(classification_report(labels_test, test_predicted_labels))\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9900691481535971\n",
      "0.777078965758211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78       717\n",
      "           1       0.78      0.77      0.78       714\n",
      "\n",
      "    accuracy                           0.78      1431\n",
      "   macro avg       0.78      0.78      0.78      1431\n",
      "weighted avg       0.78      0.78      0.78      1431\n",
      "\n",
      "32.20409893989563 seconds\n"
     ]
    }
   ],
   "source": [
    "# Using Random Forest Classification\n",
    "start = time.time()\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 10, random_state = 0)\n",
    "rfc.fit(features_train, labels_train)\n",
    "print(rfc.score(features_train, labels_train))\n",
    "print(rfc.score(features_test, labels_test))\n",
    "test_predicted_labels = rfc.predict(features_test)\n",
    "print(classification_report(labels_test, test_predicted_labels))\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "print(time_elapsed, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
